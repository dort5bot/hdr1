# utils/excel_processor.py - TAMAMEN YENƒ∞ VERSƒ∞YON
import pandas as pd
import datetime
import os
import logging
import re
from config import TURKISH_CITIES, groups, TEMP_DIR

logger = logging.getLogger(__name__)

def normalize_text(text):
    """Metni normalize et: b√ºy√ºk harf, T√ºrk√ße karakter d√ºzeltme"""
    if pd.isna(text):
        return ""
    
    # String'e √ßevir ve temizle
    text_str = str(text).strip().upper()
    
    # T√ºrk√ße karakterleri d√ºzelt
    turkish_chars = {
        'ƒ∞': 'I', 'ƒû': 'G', '√ú': 'U', '≈û': 'S', '√ñ': 'O', '√á': 'C',
        'ƒ±': 'I', 'ƒü': 'G', '√º': 'U', '≈ü': 'S', '√∂': 'O', '√ß': 'C'
    }
    
    for old, new in turkish_chars.items():
        text_str = text_str.replace(old, new)
    
    # Fazla bo≈üluklarƒ± temizle
    text_str = re.sub(r'\s+', ' ', text_str).strip()
    
    return text_str

async def process_excel_files() -> dict:
    """Process all Excel files in temp directory and group by cities"""
    results = {}
    
    logger.info(f"Excel i≈üleme ba≈üladƒ±. Temp'deki dosyalar: {os.listdir(TEMP_DIR)}")
    
    for filename in os.listdir(TEMP_DIR):
        if not filename.lower().endswith(('.xlsx', '.xls')):
            continue
            
        filepath = os.path.join(TEMP_DIR, filename)
        logger.info(f"Excel i≈üleniyor: {filename}")
        
        try:
            # Read Excel file
            df = pd.read_excel(filepath)
            logger.info(f"Dosya: {filename}, S√ºtunlar: {list(df.columns)}")
            
            # Find the city column - T√úM S√úTUNLARI DENE
            city_column = find_city_column_advanced(df, filename)
            if not city_column:
                logger.warning(f"{filename} i√ßin ≈üehir s√ºtunu bulunamadƒ±")
                continue
            
            # Process each row
            process_rows_advanced(df, city_column, results, filename)
        
        except Exception as e:
            logger.error(f"{filename} i≈ülenirken hata: {e}")
    
    logger.info(f"Excel i≈üleme tamamlandƒ±. Sonu√ß: {results}")
    return results

def find_city_column_advanced(df, filename):
    """Geli≈ümi≈ü ≈üehir s√ºtunu bulma - T√úM s√ºtunlarƒ± dene"""
    # 1. √ñnce s√ºtun isimlerinde ara
    for col in df.columns:
        col_normalized = normalize_text(col)
        
        # ≈ûehir anahtar kelimeleri (b√ºy√ºk harf)
        city_keywords = ['SEHIR', 'CITY', 'IL', 'LOCATION', 'CITY_NAME', 'ILLER', 'PROVINCE', 'SEHIRLER', 'ILCE', 'DISTRICT', 'YER']
        if any(keyword in col_normalized for keyword in city_keywords):
            logger.info(f"≈ûehir anahtarlƒ± s√ºtun bulundu: {col}")
            return col
        
        # S√ºtun isminde ≈üehir ismi ara
        if any(normalize_text(city) in col_normalized for city in TURKISH_CITIES):
            logger.info(f"≈ûehir isimli s√ºtun bulundu: {col}")
            return col
    
    # 2. S√ºtun ismi bulunamazsa, T√úM s√ºtunlardaki deƒüerlerde ara
    logger.info(f"S√ºtun isminde ≈üehir bulunamadƒ±, T√úM s√ºtunlarda deƒüerler aranacak: {filename}")
    
    # Her s√ºtunu kontrol et
    for col in df.columns:
        try:
            # ƒ∞lk 20 satƒ±rƒ± kontrol et
            city_count = 0
            for i in range(min(20, len(df))):
                cell_value = str(df.iloc[i][col]) if pd.notna(df.iloc[i][col]) else ""
                cell_normalized = normalize_text(cell_value)
                
                # H√ºcrede ≈üehir ismi var mƒ±?
                for city in TURKISH_CITIES:
                    city_normalized = normalize_text(city)
                    if city_normalized and city_normalized in cell_normalized:
                        city_count += 1
                        if city_count >= 3:  # 3'ten fazla ≈üehir bulunduysa
                            logger.info(f"≈ûehir verisi bulunan s√ºtun: {col} ({city_count} ≈üehir)")
                            return col
                        break
            
            if city_count > 0:
                logger.info(f"{col} s√ºtununda {city_count} ≈üehir bulundu")
                
        except Exception as e:
            logger.warning(f"{col} s√ºtunu kontrol edilirken hata: {e}")
    
    logger.warning(f"Hi√ßbir s√ºtunda ≈üehir verisi bulunamadƒ±: {filename}")
    return None

def process_rows_advanced(df, city_column, results, filename):
    """Geli≈ümi≈ü satƒ±r i≈üleme - B√ºy√ºk/k√º√ß√ºk harf uyumsuzluƒüunu √ß√∂z"""
    city_count = 0
    matched_cities = set()
    unmatched_cities = set()
    
    for index, row in df.iterrows():
        city = row[city_column] if pd.notna(row[city_column]) else ""
        if not city:
            continue
            
        city_str = normalize_text(city)
        city_count += 1
        
        # Find which group this city belongs to
        city_matched = False
        
        for group in groups:
            group_iller = [normalize_text(il.strip()) for il in group["iller"].split(",")]
            
            for il in group_iller:
                # Normalize edilmi≈ü deƒüerleri kar≈üƒ±la≈ütƒ±r
                if il == city_str:
                    if group["no"] not in results:
                        results[group["no"]] = []
                    if filename not in results[group["no"]]:
                        results[group["no"]].append(filename)
                        matched_cities.add(f"{city_str}->{il}")
                    city_matched = True
                    logger.debug(f"≈ûehir e≈üle≈üti: '{city_str}' -> Grup: {group['no']} ({il})")
                    break
            
            if city_matched:
                break
        
        if not city_matched:
            unmatched_cities.add(city_str)
            logger.debug(f"≈ûehir e≈üle≈ümedi: '{city_str}'")
    
    logger.info(f"{filename} i≈ülendi: {city_count} ≈üehir, {len(matched_cities)} e≈üle≈üme")
    if matched_cities:
        logger.info(f"E≈üle≈üen ≈üehirler: {sorted(matched_cities)}")
    if unmatched_cities:
        logger.warning(f"E≈üle≈ümeyen ≈üehirler: {sorted(unmatched_cities)}")

#create_group_excel Fonksiyonunu D√ºzeltelim:
# utils/excel_processor.py - create_group_excel fonksiyonunu G√úNCELLEYELƒ∞M
# utils/excel_processor.py - create_group_excel fonksiyonunu G√úNCELLEYELƒ∞M
async def create_group_excel(group_no: str, filepaths: list) -> str:
    """Create a combined Excel file for a group"""
    logger.info(f"üîÑ create_group_excel CALLED for {group_no} with {len(filepaths)} files")
    
    try:
        # Grup bilgilerini bul
        grup_info = None
        for grup in groups:
            if grup["no"] == group_no:
                grup_info = grup
                break
        
        if not grup_info:
            logger.error(f"‚ùå Group {group_no} not found in groups")
            return None
            
        logger.info(f"üìä Group info found: {grup_info['name']}")
        
        # Combine all data for this group
        all_dfs = []
        for filepath in filepaths:
            try:
                logger.info(f"üìñ Reading file: {filepath}")
                df = pd.read_excel(filepath)
                logger.info(f"‚úÖ Loaded: {os.path.basename(filepath)} - Shape: {df.shape}")
                all_dfs.append(df)
            except Exception as e:
                logger.error(f"‚ùå Error reading {filepath}: {e}")
                return None
        
        if not all_dfs:
            logger.error("‚ùå No dataframes to combine")
            return None
            
        # Combine dataframes
        try:
            combined_df = pd.concat(all_dfs, ignore_index=True)
            logger.info(f"‚úÖ Combined dataframe shape: {combined_df.shape}")
        except Exception as e:
            logger.error(f"‚ùå Error concatenating: {e}")
            return None
        
        # Generate filename
        now = datetime.datetime.now()
        timestamp = now.strftime("%Y%m%d_%H%M%S")
        filename = f"{group_no}_{grup_info['name']}_{timestamp}.xlsx"
        filepath = os.path.join(TEMP_DIR, filename)
        
        # Save the combined Excel
        try:
            combined_df.to_excel(filepath, index=False, engine='openpyxl')
            logger.info(f"‚úÖ Excel saved successfully: {filename}")
            return filepath
        except Exception as e:
            logger.error(f"‚ùå Error saving Excel: {e}")
            return None
        
    except Exception as e:
        logger.error(f"‚ùå Unexpected error in create_group_excel: {e}")
        return None
        
    except Exception as e:
        logger.error(f"‚ùå Unexpected error in create_group_excel: {e}")
        return None
